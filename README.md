# AESLC
 capestone project of Guannan LOU
 
 **Python version**: This code is in Python3.6

**Package Requirements**: torch==1.1.0 pytorch_transformers tensorboardX multiprocess pyrouge

**Updates**: For encoding a text longer than 512 tokens, for example 800. Set max_pos to 800 during both preprocessing and training.


Some codes are borrowed from PreSumm of Yang(https://github.com/nlpyang/PreSumm)

Relative models, datasets and results are saved in the Google Drive (https://drive.google.com/open?id=1VJOU1vM-eudYTnSdsje7-U0mC8x2Z1a4)


The ***BertSum AESLC.ipynb*** shows the way to preprocess the AESLC dataset and train the model;

The ***BertExt Predict.ipynb*** shows the way to generate the subject line.
