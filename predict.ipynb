{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_transformers import BertTokenizer\n",
    "\n",
    "from models import data_loader, model_builder\n",
    "from models.data_loader import load_dataset\n",
    "from models.loss import abs_loss\n",
    "from models.model_builder import AbsSummarizer\n",
    "from models.predictor import build_predictor\n",
    "from models.trainer import build_trainer\n",
    "from others.logging import logger, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# model_path = \"./checkpoints/abs\"\n",
    "# cp_file = sorted(glob.glob(os.path.join(model_path, 'model_step_*.pt')))\n",
    "# cp = cp_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model_path = './checkpoints/abs/model_step_18000.pt'\n",
    "# checkpoint = torch.load(cp, map_location=torch.device('cpu'))\n",
    "checkpoint = torch.load(cp, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'emb_size', 'enc_layers', 'enc_hidden_size', 'enc_ff_size',\n",
    "               'dec_layers', 'dec_hidden_size', 'dec_ff_size', 'encoder', 'ff_actv', 'use_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = vars(checkpoint['opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-task\", default='ext', type=str, choices=['ext', 'abs'])\n",
    "parser.add_argument(\"-encoder\", default='bert', type=str, choices=['bert', 'baseline'])\n",
    "parser.add_argument(\"-mode\", default='train', type=str, choices=['train', 'validate', 'test'])\n",
    "parser.add_argument(\"-bert_data_path\", default='../bert_data_new/cnndm')\n",
    "parser.add_argument(\"-model_path\", default='../models/')\n",
    "parser.add_argument(\"-result_path\", default='../results/cnndm')\n",
    "parser.add_argument(\"-temp_dir\", default='../temp')\n",
    "\n",
    "parser.add_argument(\"-batch_size\", default=140, type=int)\n",
    "parser.add_argument(\"-test_batch_size\", default=200, type=int)\n",
    "\n",
    "parser.add_argument(\"-max_pos\", default=512, type=int)\n",
    "parser.add_argument(\"-use_interval\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-large\", type=bool, nargs='?',const=True,default=False)\n",
    "parser.add_argument(\"-load_from_extractive\", default='', type=str)\n",
    "\n",
    "parser.add_argument(\"-sep_optim\", type=bool, nargs='?',const=True,default=False)\n",
    "parser.add_argument(\"-lr_bert\", default=2e-3, type=float)\n",
    "parser.add_argument(\"-lr_dec\", default=2e-3, type=float)\n",
    "parser.add_argument(\"-use_bert_emb\", type=bool, nargs='?',const=True,default=False)\n",
    "\n",
    "parser.add_argument(\"-share_emb\", type=bool, nargs='?', const=True, default=False)\n",
    "parser.add_argument(\"-finetune_bert\", type=bool, nargs='?', const=True, default=True)\n",
    "parser.add_argument(\"-dec_dropout\", default=0.2, type=float)\n",
    "parser.add_argument(\"-dec_layers\", default=6, type=int)\n",
    "parser.add_argument(\"-dec_hidden_size\", default=768, type=int)\n",
    "parser.add_argument(\"-dec_heads\", default=8, type=int)\n",
    "parser.add_argument(\"-dec_ff_size\", default=2048, type=int)\n",
    "parser.add_argument(\"-enc_hidden_size\", default=512, type=int)\n",
    "parser.add_argument(\"-enc_ff_size\", default=512, type=int)\n",
    "parser.add_argument(\"-enc_dropout\", default=0.2, type=float)\n",
    "parser.add_argument(\"-enc_layers\", default=6, type=int)\n",
    "\n",
    "parser.add_argument('-visible_gpus', default='-1', type=str)\n",
    "parser.add_argument('-gpu_ranks', default='0', type=str)\n",
    "parser.add_argument('-log_file', default='../logs/cnndm.log')\n",
    "parser.add_argument('-seed', default=666, type=int)\n",
    "\n",
    "parser.add_argument(\"-test_all\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-test_from\", default='')\n",
    "parser.add_argument(\"-test_start_from\", default=-1, type=int)\n",
    "\n",
    "parser.add_argument(\"-train_from\", default='')\n",
    "parser.add_argument(\"-report_rouge\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-block_trigram\", type=bool, nargs='?', const=True, default=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.gpu_ranks = [int(i) for i in range(len(args.visible_gpus.split(',')))]\n",
    "args.world_size = len(args.gpu_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.task = abs \n",
    "# args.mode = \"validate\" \n",
    "args.batch_size = 3000 \n",
    "args.test_batch_size = 500 \n",
    "args.bert_data_path = \"../bert_data/bert_data_cnndm_final/cnndm\"  \n",
    "# args.log_file = \"../logs/val_abs_bert_cnndm\"\n",
    "# args.model_path = \"../models/absext/model_step_148000.pt\" \n",
    "args.sep_optim = True \n",
    "args.use_interval = True \n",
    "args.visible_gpus = -1 \n",
    "args.max_pos = 512 \n",
    "args.max_length = 200 \n",
    "args.alpha = 0.95 \n",
    "args.min_length = 50 \n",
    "args.result_path = \"../logs/abs_bert_cnndm\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=140, bert_data_path='../bert_data_new/cnndm', block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', finetune_bert=True, gpu_ranks=[0], large=False, load_from_extractive='', log_file='../logs/cnndm.log', lr_bert=0.002, lr_dec=0.002, max_pos=512, mode='train', model_path='../models/', report_rouge=True, result_path='../results/cnndm', seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='../temp', test_all=True, test_batch_size=200, test_from='', test_start_from=-1, train_from='', use_bert_emb=False, use_interval=True, visible_gpus='-1', world_size=1)\n"
     ]
    }
   ],
   "source": [
    "for k in opt.keys():\n",
    "    if (k in model_flags):\n",
    "        setattr(args, k, opt[k])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AbsSummarizer:\n\tMissing key(s) in state_dict: \"decoder.embeddings.weight\", \"decoder.pos_emb.pe\", \"decoder.transformer_layers.0.mask\", \"decoder.transformer_layers.0.self_attn.linear_keys.weight\", \"decoder.transformer_layers.0.self_attn.linear_keys.bias\", \"decoder.transformer_layers.0.self_attn.linear_values.weight\", \"decoder.transformer_layers.0.self_attn.linear_values.bias\", \"decoder.transformer_layers.0.self_attn.linear_query.weight\", \"decoder.transformer_layers.0.self_attn.linear_query.bias\", \"decoder.transformer_layers.0.self_attn.final_linear.weight\", \"decoder.transformer_layers.0.self_attn.final_linear.bias\", \"decoder.transformer_layers.0.context_attn.linear_keys.weight\", \"decoder.transformer_layers.0.context_attn.linear_keys.bias\", \"decoder.transformer_layers.0.context_attn.linear_values.weight\", \"decoder.transformer_layers.0.context_attn.linear_values.bias\", \"decoder.transformer_layers.0.context_attn.linear_query.weight\", \"decoder.transformer_layers.0.context_attn.linear_query.bias\", \"decoder.transformer_layers.0.context_attn.final_linear.weight\", \"decoder.transformer_layers.0.context_attn.final_linear.bias\", \"decoder.transformer_layers.0.feed_forward.w_1.weight\", \"decoder.transformer_layers.0.feed_forward.w_1.bias\", \"decoder.transformer_layers.0.feed_forward.w_2.weight\", \"decoder.transformer_layers.0.feed_forward.w_2.bias\", \"decoder.transformer_layers.0.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.0.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.0.layer_norm_1.weight\", \"decoder.transformer_layers.0.layer_norm_1.bias\", \"decoder.transformer_layers.0.layer_norm_2.weight\", \"decoder.transformer_layers.0.layer_norm_2.bias\", \"decoder.transformer_layers.1.mask\", \"decoder.transformer_layers.1.self_attn.linear_keys.weight\", \"decoder.transformer_layers.1.self_attn.linear_keys.bias\", \"decoder.transformer_layers.1.self_attn.linear_values.weight\", \"decoder.transformer_layers.1.self_attn.linear_values.bias\", \"decoder.transformer_layers.1.self_attn.linear_query.weight\", \"decoder.transformer_layers.1.self_attn.linear_query.bias\", \"decoder.transformer_layers.1.self_attn.final_linear.weight\", \"decoder.transformer_layers.1.self_attn.final_linear.bias\", \"decoder.transformer_layers.1.context_attn.linear_keys.weight\", \"decoder.transformer_layers.1.context_attn.linear_keys.bias\", \"decoder.transformer_layers.1.context_attn.linear_values.weight\", \"decoder.transformer_layers.1.context_attn.linear_values.bias\", \"decoder.transformer_layers.1.context_attn.linear_query.weight\", \"decoder.transformer_layers.1.context_attn.linear_query.bias\", \"decoder.transformer_layers.1.context_attn.final_linear.weight\", \"decoder.transformer_layers.1.context_attn.final_linear.bias\", \"decoder.transformer_layers.1.feed_forward.w_1.weight\", \"decoder.transformer_layers.1.feed_forward.w_1.bias\", \"decoder.transformer_layers.1.feed_forward.w_2.weight\", \"decoder.transformer_layers.1.feed_forward.w_2.bias\", \"decoder.transformer_layers.1.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.1.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.1.layer_norm_1.weight\", \"decoder.transformer_layers.1.layer_norm_1.bias\", \"decoder.transformer_layers.1.layer_norm_2.weight\", \"decoder.transformer_layers.1.layer_norm_2.bias\", \"decoder.transformer_layers.2.mask\", \"decoder.transformer_layers.2.self_attn.linear_keys.weight\", \"decoder.transformer_layers.2.self_attn.linear_keys.bias\", \"decoder.transformer_layers.2.self_attn.linear_values.weight\", \"decoder.transformer_layers.2.self_attn.linear_values.bias\", \"decoder.transformer_layers.2.self_attn.linear_query.weight\", \"decoder.transformer_layers.2.self_attn.linear_query.bias\", \"decoder.transformer_layers.2.self_attn.final_linear.weight\", \"decoder.transformer_layers.2.self_attn.final_linear.bias\", \"decoder.transformer_layers.2.context_attn.linear_keys.weight\", \"decoder.transformer_layers.2.context_attn.linear_keys.bias\", \"decoder.transformer_layers.2.context_attn.linear_values.weight\", \"decoder.transformer_layers.2.context_attn.linear_values.bias\", \"decoder.transformer_layers.2.context_attn.linear_query.weight\", \"decoder.transformer_layers.2.context_attn.linear_query.bias\", \"decoder.transformer_layers.2.context_attn.final_linear.weight\", \"decoder.transformer_layers.2.context_attn.final_linear.bias\", \"decoder.transformer_layers.2.feed_forward.w_1.weight\", \"decoder.transformer_layers.2.feed_forward.w_1.bias\", \"decoder.transformer_layers.2.feed_forward.w_2.weight\", \"decoder.transformer_layers.2.feed_forward.w_2.bias\", \"decoder.transformer_layers.2.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.2.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.2.layer_norm_1.weight\", \"decoder.transformer_layers.2.layer_norm_1.bias\", \"decoder.transformer_layers.2.layer_norm_2.weight\", \"decoder.transformer_layers.2.layer_norm_2.bias\", \"decoder.transformer_layers.3.mask\", \"decoder.transformer_layers.3.self_attn.linear_keys.weight\", \"decoder.transformer_layers.3.self_attn.linear_keys.bias\", \"decoder.transformer_layers.3.self_attn.linear_values.weight\", \"decoder.transformer_layers.3.self_attn.linear_values.bias\", \"decoder.transformer_layers.3.self_attn.linear_query.weight\", \"decoder.transformer_layers.3.self_attn.linear_query.bias\", \"decoder.transformer_layers.3.self_attn.final_linear.weight\", \"decoder.transformer_layers.3.self_attn.final_linear.bias\", \"decoder.transformer_layers.3.context_attn.linear_keys.weight\", \"decoder.transformer_layers.3.context_attn.linear_keys.bias\", \"decoder.transformer_layers.3.context_attn.linear_values.weight\", \"decoder.transformer_layers.3.context_attn.linear_values.bias\", \"decoder.transformer_layers.3.context_attn.linear_query.weight\", \"decoder.transformer_layers.3.context_attn.linear_query.bias\", \"decoder.transformer_layers.3.context_attn.final_linear.weight\", \"decoder.transformer_layers.3.context_attn.final_linear.bias\", \"decoder.transformer_layers.3.feed_forward.w_1.weight\", \"decoder.transformer_layers.3.feed_forward.w_1.bias\", \"decoder.transformer_layers.3.feed_forward.w_2.weight\", \"decoder.transformer_layers.3.feed_forward.w_2.bias\", \"decoder.transformer_layers.3.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.3.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.3.layer_norm_1.weight\", \"decoder.transformer_layers.3.layer_norm_1.bias\", \"decoder.transformer_layers.3.layer_norm_2.weight\", \"decoder.transformer_layers.3.layer_norm_2.bias\", \"decoder.transformer_layers.4.mask\", \"decoder.transformer_layers.4.self_attn.linear_keys.weight\", \"decoder.transformer_layers.4.self_attn.linear_keys.bias\", \"decoder.transformer_layers.4.self_attn.linear_values.weight\", \"decoder.transformer_layers.4.self_attn.linear_values.bias\", \"decoder.transformer_layers.4.self_attn.linear_query.weight\", \"decoder.transformer_layers.4.self_attn.linear_query.bias\", \"decoder.transformer_layers.4.self_attn.final_linear.weight\", \"decoder.transformer_layers.4.self_attn.final_linear.bias\", \"decoder.transformer_layers.4.context_attn.linear_keys.weight\", \"decoder.transformer_layers.4.context_attn.linear_keys.bias\", \"decoder.transformer_layers.4.context_attn.linear_values.weight\", \"decoder.transformer_layers.4.context_attn.linear_values.bias\", \"decoder.transformer_layers.4.context_attn.linear_query.weight\", \"decoder.transformer_layers.4.context_attn.linear_query.bias\", \"decoder.transformer_layers.4.context_attn.final_linear.weight\", \"decoder.transformer_layers.4.context_attn.final_linear.bias\", \"decoder.transformer_layers.4.feed_forward.w_1.weight\", \"decoder.transformer_layers.4.feed_forward.w_1.bias\", \"decoder.transformer_layers.4.feed_forward.w_2.weight\", \"decoder.transformer_layers.4.feed_forward.w_2.bias\", \"decoder.transformer_layers.4.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.4.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.4.layer_norm_1.weight\", \"decoder.transformer_layers.4.layer_norm_1.bias\", \"decoder.transformer_layers.4.layer_norm_2.weight\", \"decoder.transformer_layers.4.layer_norm_2.bias\", \"decoder.transformer_layers.5.mask\", \"decoder.transformer_layers.5.self_attn.linear_keys.weight\", \"decoder.transformer_layers.5.self_attn.linear_keys.bias\", \"decoder.transformer_layers.5.self_attn.linear_values.weight\", \"decoder.transformer_layers.5.self_attn.linear_values.bias\", \"decoder.transformer_layers.5.self_attn.linear_query.weight\", \"decoder.transformer_layers.5.self_attn.linear_query.bias\", \"decoder.transformer_layers.5.self_attn.final_linear.weight\", \"decoder.transformer_layers.5.self_attn.final_linear.bias\", \"decoder.transformer_layers.5.context_attn.linear_keys.weight\", \"decoder.transformer_layers.5.context_attn.linear_keys.bias\", \"decoder.transformer_layers.5.context_attn.linear_values.weight\", \"decoder.transformer_layers.5.context_attn.linear_values.bias\", \"decoder.transformer_layers.5.context_attn.linear_query.weight\", \"decoder.transformer_layers.5.context_attn.linear_query.bias\", \"decoder.transformer_layers.5.context_attn.final_linear.weight\", \"decoder.transformer_layers.5.context_attn.final_linear.bias\", \"decoder.transformer_layers.5.feed_forward.w_1.weight\", \"decoder.transformer_layers.5.feed_forward.w_1.bias\", \"decoder.transformer_layers.5.feed_forward.w_2.weight\", \"decoder.transformer_layers.5.feed_forward.w_2.bias\", \"decoder.transformer_layers.5.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.5.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.5.layer_norm_1.weight\", \"decoder.transformer_layers.5.layer_norm_1.bias\", \"decoder.transformer_layers.5.layer_norm_2.weight\", \"decoder.transformer_layers.5.layer_norm_2.bias\", \"decoder.layer_norm.weight\", \"decoder.layer_norm.bias\", \"generator.0.weight\", \"generator.0.bias\". \n\tUnexpected key(s) in state_dict: \"ext_layer.pos_emb.pe\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.0.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.0.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.0.layer_norm.weight\", \"ext_layer.transformer_inter.0.layer_norm.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.1.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.1.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.1.layer_norm.weight\", \"ext_layer.transformer_inter.1.layer_norm.bias\", \"ext_layer.layer_norm.weight\", \"ext_layer.layer_norm.bias\", \"ext_layer.wo.weight\", \"ext_layer.wo.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f481a3f253ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbsSummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\AESLC\\models\\model_builder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, device, checkpoint, bert_from_extractive)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 845\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AbsSummarizer:\n\tMissing key(s) in state_dict: \"decoder.embeddings.weight\", \"decoder.pos_emb.pe\", \"decoder.transformer_layers.0.mask\", \"decoder.transformer_layers.0.self_attn.linear_keys.weight\", \"decoder.transformer_layers.0.self_attn.linear_keys.bias\", \"decoder.transformer_layers.0.self_attn.linear_values.weight\", \"decoder.transformer_layers.0.self_attn.linear_values.bias\", \"decoder.transformer_layers.0.self_attn.linear_query.weight\", \"decoder.transformer_layers.0.self_attn.linear_query.bias\", \"decoder.transformer_layers.0.self_attn.final_linear.weight\", \"decoder.transformer_layers.0.self_attn.final_linear.bias\", \"decoder.transformer_layers.0.context_attn.linear_keys.weight\", \"decoder.transformer_layers.0.context_attn.linear_keys.bias\", \"decoder.transformer_layers.0.context_attn.linear_values.weight\", \"decoder.transformer_layers.0.context_attn.linear_values.bias\", \"decoder.transformer_layers.0.context_attn.linear_query.weight\", \"decoder.transformer_layers.0.context_attn.linear_query.bias\", \"decoder.transformer_layers.0.context_attn.final_linear.weight\", \"decoder.transformer_layers.0.context_attn.final_linear.bias\", \"decoder.transformer_layers.0.feed_forward.w_1.weight\", \"decoder.transformer_layers.0.feed_forward.w_1.bias\", \"decoder.transformer_layers.0.feed_forward.w_2.weight\", \"decoder.transformer_layers.0.feed_forward.w_2.bias\", \"decoder.transformer_layers.0.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.0.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.0.layer_norm_1.weight\", \"decoder.transformer_layers.0.layer_norm_1.bias\", \"decoder.transformer_layers.0.layer_norm_2.weight\", \"decoder.transformer_layers.0.layer_norm_2.bias\", \"decoder.transformer_layers.1.mask\", \"decoder.transformer_layers.1.self_attn.linear_keys.weight\", \"decoder.transformer_layers.1.self_attn.linear_keys.bias\", \"decoder.transformer_layers.1.self_attn.linear_values.weight\", \"decoder.transformer_layers.1.self_attn.linear_values.bias\", \"decoder.transformer_layers.1.self_attn.linear_query.weight\", \"decoder.transformer_layers.1.self_attn.linear_query.bias\", \"decoder.transformer_layers.1.self_attn.final_linear.weight\", \"decoder.transformer_layers.1.self_attn.final_linear.bias\", \"decoder.transformer_layers.1.context_attn.linear_keys.weight\", \"decoder.transformer_layers.1.context_attn.linear_keys.bias\", \"decoder.transformer_layers.1.context_attn.linear_values.weight\", \"decoder.transformer_layers.1.context_attn.linear_values.bias\", \"decoder.transformer_layers.1.context_attn.linear_query.weight\", \"decoder.transformer_layers.1.context_attn.linear_query.bias\", \"decoder.transformer_layers.1.context_attn.final_linear.weight\", \"decoder.transformer_layers.1.context_attn.final_linear.bias\", \"decoder.transformer_layers.1.feed_forward.w_1.weight\", \"decoder.transformer_layers.1.feed_forward.w_1.bias\", \"decoder.transformer_layers.1.feed_forward.w_2.weight\", \"decoder.transformer_layers.1.feed_forward.w_2.bias\", \"decoder.transformer_layers.1.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.1.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.1.layer_norm_1.weight\", \"decoder.transformer_layers.1.layer_norm_1.bias\", \"decoder.transformer_layers.1.layer_norm_2.weight\", \"decoder.transformer_layers.1.layer_norm_2.bias\", \"decoder.transformer_layers.2.mask\", \"decoder.transformer_layers.2.self_attn.linear_keys.weight\", \"decoder.transformer_layers.2.self_attn.linear_keys.bias\", \"decoder.transformer_layers.2.self_attn.linear_values.weight\", \"decoder.transformer_layers.2.self_attn.linear_values.bias\", \"decoder.transformer_layers.2.self_attn.linear_query.weight\", \"decoder.transformer_layers.2.self_attn.linear_query.bias\", \"decoder.transformer_layers.2.self_attn.final_linear.weight\", \"decoder.transformer_layers.2.self_attn.final_linear.bias\", \"decoder.transformer_layers.2.context_attn.linear_keys.weight\", \"decoder.transformer_layers.2.context_attn.linear_keys.bias\", \"decoder.transformer_layers.2.context_attn.linear_values.weight\", \"decoder.transformer_layers.2.context_attn.linear_values.bias\", \"decoder.transformer_layers.2.context_attn.linear_query.weight\", \"decoder.transformer_layers.2.context_attn.linear_query.bias\", \"decoder.transformer_layers.2.context_attn.final_linear.weight\", \"decoder.transformer_layers.2.context_attn.final_linear.bias\", \"decoder.transformer_layers.2.feed_forward.w_1.weight\", \"decoder.transformer_layers.2.feed_forward.w_1.bias\", \"decoder.transformer_layers.2.feed_forward.w_2.weight\", \"decoder.transformer_layers.2.feed_forward.w_2.bias\", \"decoder.transformer_layers.2.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.2.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.2.layer_norm_1.weight\", \"decoder.transformer_layers.2.layer_norm_1.bias\", \"decoder.transformer_layers.2.layer_norm_2.weight\", \"decoder.transformer_layers.2.layer_norm_2.bias\", \"decoder.transformer_layers.3.mask\", \"decoder.transformer_layers.3.self_attn.linear_keys.weight\", \"decoder.transformer_layers.3.self_attn.linear_keys.bias\", \"decoder.transformer_layers.3.self_attn.linear_values.weight\", \"decoder.transformer_layers.3.self_attn.linear_values.bias\", \"decoder.transformer_layers.3.self_attn.linear_query.weight\", \"decoder.transformer_layers.3.self_attn.linear_query.bias\", \"decoder.transformer_layers.3.self_attn.final_linear.weight\", \"decoder.transformer_layers.3.self_attn.final_linear.bias\", \"decoder.transformer_layers.3.context_attn.linear_keys.weight\", \"decoder.transformer_layers.3.context_attn.linear_keys.bias\", \"decoder.transformer_layers.3.context_attn.linear_values.weight\", \"decoder.transformer_layers.3.context_attn.linear_values.bias\", \"decoder.transformer_layers.3.context_attn.linear_query.weight\", \"decoder.transformer_layers.3.context_attn.linear_query.bias\", \"decoder.transformer_layers.3.context_attn.final_linear.weight\", \"decoder.transformer_layers.3.context_attn.final_linear.bias\", \"decoder.transformer_layers.3.feed_forward.w_1.weight\", \"decoder.transformer_layers.3.feed_forward.w_1.bias\", \"decoder.transformer_layers.3.feed_forward.w_2.weight\", \"decoder.transformer_layers.3.feed_forward.w_2.bias\", \"decoder.transformer_layers.3.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.3.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.3.layer_norm_1.weight\", \"decoder.transformer_layers.3.layer_norm_1.bias\", \"decoder.transformer_layers.3.layer_norm_2.weight\", \"decoder.transformer_layers.3.layer_norm_2.bias\", \"decoder.transformer_layers.4.mask\", \"decoder.transformer_layers.4.self_attn.linear_keys.weight\", \"decoder.transformer_layers.4.self_attn.linear_keys.bias\", \"decoder.transformer_layers.4.self_attn.linear_values.weight\", \"decoder.transformer_layers.4.self_attn.linear_values.bias\", \"decoder.transformer_layers.4.self_attn.linear_query.weight\", \"decoder.transformer_layers.4.self_attn.linear_query.bias\", \"decoder.transformer_layers.4.self_attn.final_linear.weight\", \"decoder.transformer_layers.4.self_attn.final_linear.bias\", \"decoder.transformer_layers.4.context_attn.linear_keys.weight\", \"decoder.transformer_layers.4.context_attn.linear_keys.bias\", \"decoder.transformer_layers.4.context_attn.linear_values.weight\", \"decoder.transformer_layers.4.context_attn.linear_values.bias\", \"decoder.transformer_layers.4.context_attn.linear_query.weight\", \"decoder.transformer_layers.4.context_attn.linear_query.bias\", \"decoder.transformer_layers.4.context_attn.final_linear.weight\", \"decoder.transformer_layers.4.context_attn.final_linear.bias\", \"decoder.transformer_layers.4.feed_forward.w_1.weight\", \"decoder.transformer_layers.4.feed_forward.w_1.bias\", \"decoder.transformer_layers.4.feed_forward.w_2.weight\", \"decoder.transformer_layers.4.feed_forward.w_2.bias\", \"decoder.transformer_layers.4.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.4.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.4.layer_norm_1.weight\", \"decoder.transformer_layers.4.layer_norm_1.bias\", \"decoder.transformer_layers.4.layer_norm_2.weight\", \"decoder.transformer_layers.4.layer_norm_2.bias\", \"decoder.transformer_layers.5.mask\", \"decoder.transformer_layers.5.self_attn.linear_keys.weight\", \"decoder.transformer_layers.5.self_attn.linear_keys.bias\", \"decoder.transformer_layers.5.self_attn.linear_values.weight\", \"decoder.transformer_layers.5.self_attn.linear_values.bias\", \"decoder.transformer_layers.5.self_attn.linear_query.weight\", \"decoder.transformer_layers.5.self_attn.linear_query.bias\", \"decoder.transformer_layers.5.self_attn.final_linear.weight\", \"decoder.transformer_layers.5.self_attn.final_linear.bias\", \"decoder.transformer_layers.5.context_attn.linear_keys.weight\", \"decoder.transformer_layers.5.context_attn.linear_keys.bias\", \"decoder.transformer_layers.5.context_attn.linear_values.weight\", \"decoder.transformer_layers.5.context_attn.linear_values.bias\", \"decoder.transformer_layers.5.context_attn.linear_query.weight\", \"decoder.transformer_layers.5.context_attn.linear_query.bias\", \"decoder.transformer_layers.5.context_attn.final_linear.weight\", \"decoder.transformer_layers.5.context_attn.final_linear.bias\", \"decoder.transformer_layers.5.feed_forward.w_1.weight\", \"decoder.transformer_layers.5.feed_forward.w_1.bias\", \"decoder.transformer_layers.5.feed_forward.w_2.weight\", \"decoder.transformer_layers.5.feed_forward.w_2.bias\", \"decoder.transformer_layers.5.feed_forward.layer_norm.weight\", \"decoder.transformer_layers.5.feed_forward.layer_norm.bias\", \"decoder.transformer_layers.5.layer_norm_1.weight\", \"decoder.transformer_layers.5.layer_norm_1.bias\", \"decoder.transformer_layers.5.layer_norm_2.weight\", \"decoder.transformer_layers.5.layer_norm_2.bias\", \"decoder.layer_norm.weight\", \"decoder.layer_norm.bias\", \"generator.0.weight\", \"generator.0.bias\". \n\tUnexpected key(s) in state_dict: \"ext_layer.pos_emb.pe\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.0.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.0.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.0.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.0.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.0.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.0.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.0.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.0.layer_norm.weight\", \"ext_layer.transformer_inter.0.layer_norm.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_keys.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_values.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_values.bias\", \"ext_layer.transformer_inter.1.self_attn.linear_query.weight\", \"ext_layer.transformer_inter.1.self_attn.linear_query.bias\", \"ext_layer.transformer_inter.1.self_attn.final_linear.weight\", \"ext_layer.transformer_inter.1.self_attn.final_linear.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_1.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_1.bias\", \"ext_layer.transformer_inter.1.feed_forward.w_2.weight\", \"ext_layer.transformer_inter.1.feed_forward.w_2.bias\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.weight\", \"ext_layer.transformer_inter.1.feed_forward.layer_norm.bias\", \"ext_layer.transformer_inter.1.layer_norm.weight\", \"ext_layer.transformer_inter.1.layer_norm.bias\", \"ext_layer.layer_norm.weight\", \"ext_layer.layer_norm.bias\", \"ext_layer.wo.weight\", \"ext_layer.wo.bias\". "
     ]
    }
   ],
   "source": [
    "model = AbsSummarizer(args, device, checkpoint)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
